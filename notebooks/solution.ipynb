{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "creative-pattern",
   "metadata": {},
   "source": [
    "## PHME 2022 Data Challenge\n",
    "\n",
    "This is the skeleton of the Jupyter Notebook you have to fill.\n",
    "The Notebook must define three functions, each for solving a separate classification task of the challenge.\n",
    "They are `classification_1`, `classification_2` and `classification_3` and must solve, respectively, task 1, 2 and 3 of the challenges.\n",
    "\n",
    "**Automatic Scoring and Leader Board:** \n",
    "For each participant, we will consider the file locate in `data-challenge-phme/solution.ipynb` as proposed solution. We will execute the Notebook and, in the end, invoke the functions with the test data.\n",
    "We will evaluate the output of the functions and compute the performance on it.\n",
    "\n",
    "**Note:** if the execution of the notebook leads to an error or an exception, the functions will not be defined and we will not evaluate the performance of your solution.\n",
    "\n",
    "**Note:** the notebook must have a reasonable execution time. We will not evaluate notebooks requiring more than **10 minutes** to be executed.\n",
    "If you want to train complex models that require a large amount of time, do it in a separate notebook. Thus, in `solution.ipynb`, load pre-trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "local-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input is the SPI data in form of a Pandas DataFrame, exactly as it is read with pd.read_csv()\n",
    "# The output must be the list of predicted defects. Each defect is a tuple (Panel, Figure, Component)\n",
    "\n",
    "def classification_1 (spi):\n",
    "    \n",
    "    defects = [\n",
    "        (\"26319086100520102844\", \"4\", \"R20\"),\n",
    "        (\"25319072500520102844\", \"1\", \"U5\"),\n",
    "        (\"25319072500520102844\", \"2\", \"U1\"),\n",
    "    ]\n",
    "    return defects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "incident-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first input is the SPI data in form of a Pandas DataFrame, exactly as it is read with pd.read_csv()\n",
    "# The second input is the AOI data. OperatorLabel and RepairLabel are not included, as you must predict OperatorLabel\n",
    "# The output must be the classification result. Each entry is a tuple (Panel, Figure, Component, PredictedOperatorLabel)\n",
    "\n",
    "def classification_2 (spi, aoi):\n",
    "    \n",
    "    predicted = [\n",
    "        (\"26319044800520102844\", \"2\", \"C31\", \"Good\"),\n",
    "        (\"25319072500520102844\", \"1\", \"U2\", \"Good\"),\n",
    "        (\"26319063400520102844\", \"6\", \"L2\", \"Bad\"),\n",
    "    ]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "greek-range",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The first input is the SPI data in form of a Pandas DataFrame, exactly as it is read with pd.read_csv()\n",
    "# The second input is the AOI data. RepairLabel are not included, as you must predict it\n",
    "# The output must be the classification result. Each entry is a tuple (Panel, Figure, Component, PredictedRepairLabel)\n",
    "\n",
    "def classification_3 (spi, aoi):\n",
    "    \n",
    "    predicted = [\n",
    "        (\"26319063400520102844\", \"6\", \"L2\", \"FalseScrap\"),\n",
    "        (\"25319072500520102844\", \"1\", \"U3\", \"NotPossibleToRepair\"),\n",
    "        (\"25319072500520102844\", \"2\", \"U1\", \"NotPossibleToRepair\"),\n",
    "    ]\n",
    "    return predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "peaceful-anime",
   "metadata": {},
   "source": [
    "## Test the code\n",
    "\n",
    "In the following, we report a code that you can use to test if your script correctly handles the data.\n",
    "\n",
    "We will use a very similar piece of code to run your Notebook to build the leaderboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "latest-brand",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/bigdatalab_cpu_202101/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3427: DtypeWarning: Columns (17) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import math\n",
    "import glob\n",
    "\n",
    "dfs = []\n",
    "for f in glob.glob(\"data/SPI_*.csv.zip\"):\n",
    "    dfs.append(pd.read_csv(f))\n",
    "SPI = pd.concat(dfs)\n",
    "\n",
    "dfs = []\n",
    "for f in glob.glob(\"data/AOI_*.csv.zip\"):\n",
    "    dfs.append(pd.read_csv(f))\n",
    "AOI = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "whole-surveillance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score Task 1: 7.268234182505361e-05\n",
      "F1 Score Task 2: 0.004842615012106537\n",
      "F1 Score Task 3: 0.008130081300813009\n",
      "Final Score: 0.004348459551581533\n"
     ]
    }
   ],
   "source": [
    "results_1 = set(classification_1(SPI))\n",
    "results_2 = classification_2(SPI, AOI[[\"PanelID\",\"FigureID\",\"MachineID\",\"ComponentID\",\"PinNumber\",\"AOILabel\"]])\n",
    "results_3 = classification_3(SPI, AOI[[\"PanelID\",\"FigureID\",\"MachineID\",\"ComponentID\",\"PinNumber\",\"AOILabel\",\"OperatorLabel\"]])\n",
    "\n",
    "# Performance Task 1\n",
    "groundtruth_1  = {tuple( [str(f) for f in e] ) for e in AOI[[\"PanelID\",\"FigureID\",\"ComponentID\"]].values}\n",
    "precision_1    = len(results_1&groundtruth_1)/len(results_1) if len(results_1) > 0 else 0\n",
    "recall_1       = len(results_1&groundtruth_1)/len(groundtruth_1) if len(groundtruth_1) > 0 else 0\n",
    "f1_1           = 2*precision_1*recall_1/(precision_1+recall_1) if precision_1+recall_1 > 0 else 0\n",
    "\n",
    "# Performance Task 2\n",
    "results_dict_2 = { (str(p), str(f), str(c)):l for p, f, c, l in results_2}\n",
    "validationdata_2 = []\n",
    "for t in AOI.drop_duplicates(subset=[\"PanelID\",\"FigureID\",\"ComponentID\"], keep=\"first\").itertuples():\n",
    "    predicted = results_dict_2.get(( str(t.PanelID), str(t.FigureID), str(t.ComponentID)), \"-\" )\n",
    "    validationdata_2.append((t.PanelID, t.FigureID, t.ComponentID, t.OperatorLabel, predicted))\n",
    "validationdata_2 = pd.DataFrame(validationdata_2, columns = [\"PanelID\",\"FigureID\",\"ComponentID\", \"Real\", \"Predicted\"]) \n",
    "f1_2 = classification_report(validationdata_2[\"Real\"], validationdata_2[\"Predicted\"],output_dict=True)[\"Bad\"][\"f1-score\"]\n",
    "\n",
    "# Performance Task 3\n",
    "results_dict_3 = { (str(p), str(f), str(c)):l for p, f, c, l in results_3}\n",
    "validationdata_3 = []\n",
    "for t in AOI[AOI[\"RepairLabel\"].isin({\"FalseScrap\",\"NotPossibleToRepair\"})]\\\n",
    "        .drop_duplicates(subset=[\"PanelID\",\"FigureID\",\"ComponentID\"], keep=\"first\").itertuples():\n",
    "    predicted = results_dict_3.get(( str(t.PanelID), str(t.FigureID), str(t.ComponentID)), \"-\" )\n",
    "    validationdata_3.append((t.PanelID, t.FigureID, t.ComponentID, t.RepairLabel, predicted))\n",
    "validationdata_3 = pd.DataFrame(validationdata_3, columns = [\"PanelID\",\"FigureID\",\"ComponentID\", \"Real\", \"Predicted\"]) \n",
    "cr = classification_report(validationdata_3[\"Real\"], validationdata_3[\"Predicted\"],output_dict=True)\n",
    "f1_3 = (cr[\"FalseScrap\"][\"f1-score\"] + cr[\"NotPossibleToRepair\"][\"f1-score\"])/2\n",
    "\n",
    "print(\"F1 Score Task 1:\", f1_1)\n",
    "print(\"F1 Score Task 2:\", f1_2)\n",
    "print(\"F1 Score Task 3:\", f1_3)\n",
    "print(\"Final Score:\", statistics.mean([f1_1, f1_2, f1_3]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
